---
title: "Digit-memorization"
author: "Ellisiv Sætherø Steen, Johanne Skogvang"
date: "05/03 2019"
output: pdf_document
---

# Introduction
  Memory is one of the most important features of the human brain. Without it, humans would not be able to learn anything, and it is necessary for the daily functionality. 
  An important part of the memory is the short-term memory, which is the brains capacity to remeber a small amount of information for a small period of time. If we know how to utilize our capacity in the best possible way, we will be able to remember more efficiently and hopefully 
  
  
  From before, we know that the short-term memory has about the capacity to remember seven, plus or minus two, items at the same time. Our goal is to test wheter this holds or not. 


# Selection of factors and response  
  The first thing we tested was to memorize words. A list of wors was given to the test person, from which she tried to memorize as many words as possible. This was tested with different factors, and two different persons. Each time the number of words memorized, without exception, was six. Hence, we decided to give the same experiment a try, only exchanging worsd with digits. This resulted in a much higher variance than when we tried memorizing words. 
  The factors we think are relevant when testing the short term memory is the amount of time the test person gets to look at the digits, wheter the person is disturbed between memorizing and writing down the digits or not and wheter she is allowed to use aids, such as pen and paper, while looking at the digits. 
  We expect an interraction between time and aid, thinking that they will amplify each other. For each of the factors we think that two levels will be the most suitable, i.e. short and long time to look at the digits, disturbance or not between looking at the digits and writing the down and wheter she gets to use aids or not. One could argue for three levelsof time, but we believe that two levels will be suficient if one for example double the amount of time.
  Also, we think that it is easy to control that the factors are at the desired level since we can measure the time, choose to use aids or not and we can make sure of disturbance or not our self. 

  A response variable that will give the information we need is the number of digits the test person remembers in the right order until the first mistake, meaning that if the first digit is wrong, you get Y equal to zero, regardless of the correctness of the next digits. In theory the test person gets an infinite number of digits, but since time is limited, one can also limit the number of digits given, and still count it as infinite. One could also chose to get a finite number of digits or numbers, and count the amount that is in the right spot. There are also a lot of different variations one could do when counting the amount og numbers that the test person are able to memorize, the most important thing is that one are consistent. As mentioned, one could also count words instead of digits. The accuracy when using the first response variable is 100% since we easily can count how many digits there are until the first mistake. 
  



# Choice of design 
We choose a full $2^k$ factorial experiments with replicate because of the simple nature of the experiment. One full trial does not need complicated equipment and replication causes minimal resources. The only problem with doing multiple experiments is that the test person gets tired and it is hard to reset between rounds. Because of that we choose to use two different test people and do one full trial with both of them. The result is a $2^4$ factorial design with $2^5$ experiments. Because of the different test people it is necessary to divide the design into two blocks, one block representing a test person. This is needed because the memory of the test people can differ, so the block factor needs to compensate for this. 

# Experimental set-up
We chose the factors discussed above, but the value of the two levels needs to be determined and we need to choose some guidelines to make the experiments consistent. The two time intervals needs to be sufficiently different, but at the same time we do not want to have too long time intervals to cause as little as possible exhaustion for the test persons. We decide on the short interval, coded as $time = -1$, to be $30$sec and the long time interval, coded as $time = 1$, to be $60$sec. The aids provided is pen and paper and the possibility of speaking out loud. To not make this a writing contest the paper is taken away from the test person after the time for memorizing is up. To make the task a bit more challenging the test people get 15 seconds break between momorizing and writing down their final answer. This time is constant and is thus not a factor in our trials. It is also in this period the person could be disturbed. After some discussion we choose that there should just be loud talking in the background which needs no respons from the test person, or else it would be too hard to remember anything.  
To explore the quality of our experiments, we include a variable which we assume will have no effect on the result, which is if the test person is wearing shoes. Because we do a limited amount of experiments it is interessting to see if the random variable will be included in the final model we choose. To minimize the influence of the experimental order and to exlude time as a factor we randomize the order of the experiments for both trials.  
There are several challenges when measuring the response variable. First of all the digits needs to be totally random and different every time. To solve this we use the functionality of the web-page Wolfram-Alpha. For every test run it generates a new random number with 40 digits which makes the test runs independent. Another challenge is the measurement of the quality of the response. What if the first digits are wrong, but others are rightly placed? And what if a digit is excluded and that shifts the order of the rest of the answer? To make the rules simple and consistent, we then decided the response, $y$, to be the number of digits rightly guessed up to the first mistake. 

# Results

```{r design, include=T}
#install.packages('FrF2')
library(FrF2)

plan <- FrF2(nruns = 32, nfactors=5, randomize = F)

y <- c(9, 9, 9, 4, 6, 15, 6, 3, 11, 15, 12, 12, 5, 12, 6, 1, 9, 15, 9, 11, 12, 12, 6, 12, 12, 0, 9, 15, 7, 15, 6, 9)
plan <- add.response(plan, y)
#plan <- plan[, -4]
lm4 <- lm(y~(A + B + C + D)^4 + E, data=plan)
summary(lm4)

```
The results of the experiment is shown above in the summary.  
A1 = Long time for memorization  
B1 = Available aids  
C1 = Presence of disturbance  
D1 = Wearing shoes
E = Block factor/test person  
For a $2^k$ factorial experiment, we are doing inference on the main effects, $2\beta_j$. The resulting model is thus

$$\hat{y_i} = 9.19 + 0.81A - 1.06B - 0.88C + 0D + 0.75E - 0.56AB + 0.75AC - 0.12AD  - 1.12BC + 0.62BD-0.69CD- 0.87ABC + 0.37ABD+ 0.19ACD- 0.56BCD- 1.06ABCD$$
We see from the p-values in the summary that none of the factors are characterized to be non-zero with a certainty of more than 85%, wich is not good at all. We inspect the residual plot to see if this can give more insight in the quality of our measurements.

## Experimental weaknesses  
```{r residual plot}
rres <- rstudent(lm4)
plot(lm4$fitted,rres, title("Studentized residual plot"))

qqnorm(rres)
qqline(rres)

library(nortest)
ad.test(rstudent(lm4))
```

We look at the residual plot and the Anderson-Darling test and see that our residuals does not look very normally distributed. This is probably caused by some very unlikely obeservations, like the two outliers visible in the residual plot. We therefore discuss what went wrong in the experiment to try to find an explaination. The implementation went more or less as we planned. It happened in the first trial that we read the randomized design matrix wrong and thus switched the order of two of the tests. As we see it, this did not affect the trial because the order was random and thus a random switch will not lead to a loss of randomization. We also observed that some sequences of digits were easier to remember than others. Also, the number generator had an output of blocks of three digits, and thus there were an overrepresentation in the responses of numbers dividable of three. It is also possible that the blocks made it easier to remember. These kind of factors could have lead to some extreme observations. Additionally we had some problems because of our simple measurement of response. One time the test person failed to remember the first digit, whih lead to $y=0$ even though the person remembered many other digits right. This is a major flaw in our experiment because if the test person does an early mistake it does not need to say much abouth his or her memory.  
#Also the experiment was done in unpredictable surroundings, where people walked by and talked among other things. It was therefore a bit variety in the disturbance-factor, but it was not much difference and because of the random order, it is not unreasonable to assume that this did not affect the result much.
We conclude that the observation that felt most problematic during the trials were observation $y_{26}=0$. By inspecting our residual plot we find that two observations deviate significantly from the rest. Below we find that observation $y_{26}$ is one of those outliers, more specifically the point with fitted value around 8 and residual -4.
```{r y=0}
cat("Fitted value of observation 26: ", lm4$fitted.values[26], ". Studentized residual: ", rres[26])

```

## Modified results  
To remove the problematic outlier we have chosen to imputate the observation using mean substitution. We set $y_{26}=\text{mean}(y)$ and fit a new model. The nice things about using mean substitution is that unlike removing the observation we still get the properties of a two-factor experiment. The main problem with doing this is that it provides a kind of false sense of security and we can not trust the results as much as the it looks like. It will also very likely lead to smooth out the effects of the factors. This is obvious if we use the same technique on more observations, and ultimately for all, then no factors would have any effect. 
```{r modified, include=F}
planmod <- FrF2(nruns = 32, nfactors=5, randomize = F)
ymod <- y
ymod[26] <- lm4$coefficients[1] #mean of the observations
modified <- lm(ymod~(A + B + C + D)^4 + E, data=planmod)
summary(modified)

rresmod <- rstudent(modified)
plot(modified$fitted,rresmod, title("Studentized residual plot for modified model"))

qqnorm(rresmod)
qqline(rresmod)

library(nortest)
ad.test(rstudent(modified))

```
This model provides more significant results and we observe from the Anderson-Darling test and the studentized residual plot that the residuals also look more like random noise. We choose to move forward with the new model because as we discussed above, an early mistake does not need to mean much about the persons memory, but we also have in mind that we have manipulated our data which will influence our results. 
  Moving on, we analyze the new effects and use the fact that the standard deviation of the model is t-distributed to find the significant effects with significance level $\alpha = 0.05$.

```{r effects}
effects <- 2*modified$coeff
effects

n <- length(ymod)
sest <- summary(modified)$sigma

seffect <- 2*sest/sqrt(n) # SD of 2*beta-hat

signcut <- qt(0.975,df=n-2^4)*seffect

barplot(sort(abs(effects[-1]),decreasing=FALSE),las=1,horiz=TRUE)
abline(v=signcut,col=2,lwd=2)
```
We see from the bar plot that the factors $B$ and $C$ corresponding to "Available aids" and "Presence of disturbance" is the only factors considered significant with significance level $\alpha = 0.05$. We also observe that there are not any factors or interactions that really stick out, and this reinforces the theory that the effects would be smoothed out by the mean substitution. The resulting model is anyways

$$y_i = 9.47 - 1.35 x_\text{aids} - 1.16 x_\text{disturbance},$$ where $x_\text{aids}, x_\text{disturbance} \in \{-1, 1\}$.

# Conclusion
We have seen from the trials and the analysis afterwards that a well planned experiments is key. The main problem in our case was the choice of response, where we thought that the easiest choice would be good enough. Even though it is important to use a response which is easy to understand and measure, it looks like we could have gotten better results by finding a more complicated, but more accurate measurement of how many digits that were remembered.
  From the analysis we found that there was mainly one observation that made inference particularly hard. We used mean substitution on this observaton, which really improved the residual plots and the significance of our factors. 
  Even though we got some results from our experiments, we will be carful when concluding because of our poor choice of response measurements and because we interferred with the results. Despite this, we have found some results indicating that the use of writing down what you want to remember actually does not help. Probably it is poor spending of time and from the execution of the experiments it seemed like the test people remembered the numbers better, but did not make it as far. The other indication was that it is harder to remember if you are in a noisy environment. This was hardly no surprize, but we had maybe thought that this would have even bigger effect and that this would be worse than having aids available.
  The other factors are harder to interprete, but we can see in the bar plot that factor $D$ hat little, if any significance and this is completely consistent with our expectations. Also we can see from the summary that the second test person remembered a little better, and this is just expected variations in the population.
  To summarize, we would recommend doing the experiments agian with a slight change of response measurement. A good alternative is to count all the rightly placed digits and give some kind of penalty for wrongly placed digits. This would hopefully prevent extreme observations in the low area and it gives a more accurate estimate of memorization. Maybe it is also a good idea to exchange some of the factors. From our analysis it seems rather clear that shoes has nothing to do with memory, so it could be smart to just discard it as a facor.

